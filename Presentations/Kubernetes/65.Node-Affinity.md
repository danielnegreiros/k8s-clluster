# Node Affinity 

Node Affinity has similar concept to Node-Selector.\
But it has some improvements:

- You can set multiple values for a key
    - example: if disktype is equal to ssh or hdd or typex
- You can use expressions like NotIn
- You can use preferable.
    - That means if the scheduler doesn't find the exact label it can still go on.

2 main types:
- requiredDuringSchedulingIgnoredDuringExecution
- preferredDuringSchedulingIgnoredDuringExecution

Syntax for each one of them.\
Code taken from: https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#affinity-and-anti-affinity
```
  affinity:
    nodeAffinity:
      requiredDuringSchedulingIgnoredDuringExecution:
        nodeSelectorTerms:
        - matchExpressions:
          - key: kubernetes.io/e2e-az-name
            operator: In
            values:
            - e2e-az1
            - e2e-az2
      preferredDuringSchedulingIgnoredDuringExecution:
      - weight: 1
        preference:
          matchExpressions:
          - key: another-node-label-key
            operator: In
            values:
            - another-node-label-value
```
Make sure our nodes are labeled just like previous examples

```
$ kubectl label node worker01 disk=hdd
node/worker01 labeled

$ kubectl label node worker01 disk=ssd
node/worker02 labeled
```

- Checking nodes labels
```
$ kubectl get nodes --show-labels
NAME       STATUS     ROLES    AGE     VERSION   LABELS
master     Ready      master   6h13m   v1.19.3   beta.kubernetes.io/arch=amd64,beta.kubernetes.io/os=linux,kubernetes.io/arch=amd64,kubernetes.io/hostname=master,kubernetes.io/os=linux,node-role.kubernetes.io/master=
worker01   Ready      <none>   6h4m    v1.19.3   beta.kubernetes.io/arch=amd64,beta.kubernetes.io/os=linux,disk=hhd,kubernetes.io/arch=amd64,kubernetes.io/hostname=worker01,kubernetes.io/os=linux
worker02   NotReady   <none>   5h56m   v1.19.3   beta.kubernetes.io/arch=amd64,beta.kubernetes.io/os=linux,disk=ssd,kubernetes.io/arch=amd64,kubernetes.io/hostname=worker02,kubernetes.io/os=linux
```

Now let's create four pods:
- required disk = typex (This one should go pending)
- preferable disk = typex (This one should go worker01 or worker02)
- required disk = not ssd  (This one should go worker01)
- required disk = sshd or hdd (This one should go worker01 or worker02)

--

- First POD

```
cat << EOF > required-type-x.yaml
apiVersion: v1
kind: Pod
metadata:
  creationTimestamp: null
  labels:
    run: required-type-x
  name: required-type-x
spec:
  affinity:
    nodeAffinity:
      requiredDuringSchedulingIgnoredDuringExecution:
        nodeSelectorTerms:
        - matchExpressions:
          - key: disk
            operator: In
            values:
            - typex
  containers:
  - image: nginx
    name: required-type-x
    resources: {}
  dnsPolicy: ClusterFirst
  restartPolicy: Always
status: {}
EOF
```
Apply 
```
$ kubectl apply -f required-type-x.yaml
pod/required-type-x created
```

- Second POD
```
cat << EOF > preferable-type-x.yaml
apiVersion: v1
kind: Pod
metadata:
  creationTimestamp: null
  labels:
    run: preferable-type-x
  name: preferable-type-x
spec:
  affinity:
    nodeAffinity:
      preferredDuringSchedulingIgnoredDuringExecution:
      - weight: 1
        preference:
          matchExpressions:
          - key: disk
            operator: In
            values:
            - typex    
  containers:
  - image: nginx
    name: preferable-type-x
    resources: {}
  dnsPolicy: ClusterFirst
  restartPolicy: Always
status: {}
EOF
```

- Apply
```
$ kubectl apply -f preferable-type-x.yaml
pod/preferable-type-x created

```

- Third POD
```
cat << EOF > required-type-not-ssd.yaml
apiVersion: v1
kind: Pod
metadata:
  creationTimestamp: null
  labels:
    run: required-type-not-ssd
  name: required-type-not-ssd
spec:
  affinity:
    nodeAffinity:
      requiredDuringSchedulingIgnoredDuringExecution:
        nodeSelectorTerms:
        - matchExpressions:
          - key: disk
            operator: NotIn
            values:
            - ssd
  containers:
  - image: nginx
    name: required-type-not-ssd
    resources: {}
  dnsPolicy: ClusterFirst
  restartPolicy: Always
status: {}
EOF
```
- Apply 
```
$ kubectl apply -f required-type-not-ssd.yaml
pod/required-type-not-ssd created
```

- Fourth and Last
```
cat << EOF > required-one-of-2-types.yaml
apiVersion: v1
kind: Pod
metadata:
  creationTimestamp: null
  labels:
    run: required-one-of-2-types
  name: required-one-of-2-types
spec:
  affinity:
    nodeAffinity:
      requiredDuringSchedulingIgnoredDuringExecution:
        nodeSelectorTerms:
        - matchExpressions:
          - key: disk
            operator: In
            values:
            - ssd
            - hdd
  containers:
  - image: nginx
    name: required-one-of-2-types
    resources: {}
  dnsPolicy: ClusterFirst
  restartPolicy: Always
status: {}
EOF
```
- Apply 
```
$ $ kubectl apply -f required-one-of-2-types.yaml
pod/required-one-of-2-types created
```

- Checking all PODs and their nodes
```
$ kubectl get pods -o wide
NAME                      READY   STATUS    RESTARTS   AGE     IP          NODE       NOMINATED NODE   READINESS GATES
preferable-type-x         1/1     Running   0          9m22s   10.36.0.1   worker02   <none>           <none>
required-one-of-2-types   1/1     Running   0          34s     10.36.0.2   worker02   <none>           <none>
required-type-not-ssd     1/1     Running   0          79s     10.44.0.6   worker01   <none>           <none>
required-type-x           0/1     Pending   0          16m     <none>      <none>     <none>           <none>
```

Let's get back our summary and check:

- required disk = typex (This one should go pending) - OK
- preferable disk = typex (This one should go worker01 or worker02) - OK
- required disk = not ssd  (This one should go worker01) - OK
- required disk = sshd or hdd (This one should go worker01 or worker02) - OK

- Let's take a look at some Logs:

```
$ kubectl describe pod | grep "Name:\|scheduler" | grep -v Secret
Name:         preferable-type-x
  Normal  Scheduled  11m   default-scheduler  Successfully assigned default/preferable-type-x to worker02
Name:         required-one-of-2-types
  Normal  Scheduled  3m2s   default-scheduler  Successfully assigned default/required-one-of-2-types to worker02
Name:         required-type-not-ssd
  Normal  Scheduled  3m47s  default-scheduler  Successfully assigned default/required-type-not-ssd to worker01
Name:         required-type-x
  Warning  FailedScheduling  74s (x15 over 19m)  default-scheduler  0/3 nodes are available: 3 node(s) didn't match node selector.
```

For required type x, scheduler didn't find any matching node


##### To practice, type in your terminal:
Under Development

[<==](60.Node-Selector.md) 
&emsp; 
[Home](../../README.md) 
&emsp; 
[==>]()