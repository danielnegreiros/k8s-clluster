# Taints and Tolerations

### Taints

Think of taint as a mechanism to prevent PODs to be scheduled on a certain node.


So let's say the node worker01 is kind of unstable lately, and we want no new PODs schedule on it.

create a taint in our worker01. 

```
$ kubectl taint nodes worker01 status=unstable:NoSchedule
node/worker01 tainted
```

- How can we check that? There are many beautiful ways but let's use the famous grep
```
$ kubectl describe nodes worker01 | grep -i taint
Taints:             status=unstable:NoSchedule
```

- Now let's create a deployment with 8 replicas and see how that works out.
```
$ kubectl create deployment my-nginx-deploy --image=nginx --replicas=8 --dry-run=client -o yaml > my-8-deploy.yaml

$ kubectl apply -f my-8-deploy.yaml
deployment.apps/my-nginx-deploy configured
```

- As you can see all PODs are being schedule to worker02. Because worker01 is tainted
```
$ kubectl get pods -o wide
NAME                               READY   STATUS              RESTARTS   AGE   IP          NODE       NOMINATED NODE   READINESS GATES
my-nginx-deploy-7cf7fcb759-98whh   1/1     Running             0          17s   10.36.0.2   worker02   <none>           <none>
my-nginx-deploy-7cf7fcb759-9sszr   1/1     Running             0          17s   10.36.0.3   worker02   <none>           <none>
my-nginx-deploy-7cf7fcb759-b9xtp   0/1     ContainerCreating   0          17s   <none>      worker02   <none>           <none>
my-nginx-deploy-7cf7fcb759-f9g2z   0/1     ContainerCreating   0          17s   <none>      worker02   <none>           <none>
my-nginx-deploy-7cf7fcb759-fnzgj   1/1     Running             0          17s   10.36.0.4   worker02   <none>           <none>
my-nginx-deploy-7cf7fcb759-nm7fn   0/1     ContainerCreating   0          17s   <none>      worker02   <none>           <none>
my-nginx-deploy-7cf7fcb759-snktk   1/1     Running             0          17s   10.36.0.1   worker02   <none>           <none>
my-nginx-deploy-7cf7fcb759-wzjz5   0/1     ContainerCreating   0          17s   <none>      worker02   <none>           <none>
```

### Tolerations

Ok, So if you have a POD or Deployments that don't care about the taint.
In our case, don't care worker01 is unstable.

Let's create a toleration for the deployment.

- Edit my-8-deploy.yaml and add under POD (template) spec:

```
tolerations:
- key: "status"
  operator: "Equal"
  value: "unstable"
  effect: "NoSchedule"
```

Final result like this:

- Execute
```
$ kubectl apply -f my-8-deploy.yaml
deployment.apps/my-nginx-deploy configured
```

- After a while

```
$ kubectl get all -o wide
NAME                                   READY   STATUS    RESTARTS   AGE   IP          NODE       NOMINATED NODE   READINESS GATES
pod/my-nginx-deploy-7bbc48dff6-bfddh   1/1     Running   0          76s   10.44.0.7   worker01   <none>           <none>
pod/my-nginx-deploy-7bbc48dff6-bkv7d   1/1     Running   0          77s   10.44.0.6   worker01   <none>           <none>
pod/my-nginx-deploy-7bbc48dff6-cdb4p   1/1     Running   0          76s   10.36.0.7   worker02   <none>           <none>
pod/my-nginx-deploy-7bbc48dff6-crxpp   1/1     Running   0          67s   10.36.0.3   worker02   <none>           <none>
pod/my-nginx-deploy-7bbc48dff6-h6kfj   1/1     Running   0          71s   10.44.0.8   worker01   <none>           <none>
pod/my-nginx-deploy-7bbc48dff6-hrmj8   1/1     Running   0          70s   10.36.0.5   worker02   <none>           <none>
pod/my-nginx-deploy-7bbc48dff6-pwlw6   1/1     Running   0          77s   10.36.0.6   worker02   <none>           <none>
pod/my-nginx-deploy-7bbc48dff6-qlqqx   1/1     Running   0          68s   10.44.0.9   worker01   <none>           <none>
```

Apart from Noschedule effect, we have:
- PreferNoSchedule: it will try to not schedule
- NoExecute: It will evict running PODs

- NoSchedule: It will not schedule new PODs (the one we just used)


Let's delete deployment
```
$ kubectl delete -f my-8-deploy.yaml
deployment.apps "my-nginx-deploy" deleted
```

Let's remove taint (same command appending a '-')
```
$ kubectl taint nodes worker01 status=unstable:NoSchedule-
node/worker01 untainted
```

##### To practice, type in your terminal:
Under Development

[<==](47.Services-Cluster-LoadBalancer.md) 
&emsp; 
[Home](../../README.md) 
&emsp; 
[==>](55.Manual-Scheduling.md)